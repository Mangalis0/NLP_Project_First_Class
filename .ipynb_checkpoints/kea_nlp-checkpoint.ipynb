{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     RT @thenation: Mike Pence doesn’t believe in g...\n",
       "7     RT @makeandmendlife: Six big things we can ALL...\n",
       "8     @AceofSpadesHQ My 8yo nephew is inconsolable. ...\n",
       "9     RT @paigetweedy: no offense… but like… how do ...\n",
       "10    RT @StephenSchlegel: she's thinking about how ...\n",
       "11    I do hope people who are vocal about climate c...\n",
       "12    RT @tveitdal: We only have a 5 percent chance ...\n",
       "13    RT @Alifaith55: Oh. My. God.\\n\\nTrump's Govern...\n",
       "14    Fossil fuel giant ExxonMobil ‘misled’ the publ...\n",
       "15    RT @GlblCtzn: 'I don't wanna live forever – an...\n",
       "16    RT @jackholmes0: Issues scrubbed from https://...\n",
       "17    RT @patagonia: If our elected leaders fail to ...\n",
       "18    RT @SenSanders: We have a president-elect who ...\n",
       "19    Calum: *tweets abt reunitingish w the cast*\\n-...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['message'].iloc[6:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['message'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "message      0\n",
       "tweetid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15819\n",
      "15819\n"
     ]
    }
   ],
   "source": [
    "print(len(data['message']))\n",
    "print(len(data['message'].apply(lambda x: x.isspace())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  tweetid\n",
       "0         -1     1296\n",
       "1          0     2353\n",
       "2          1     8530\n",
       "3          2     3640"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dist = data.groupby('sentiment')[['tweetid']].count()\n",
    "sent_dist.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAWoUlEQVR4nO3df7AdZ33f8fcHyRjxQ4NVXzlCUiO3\nUaGyKSa6owjcEoJJrCQNUilOxQyxoO4o4zEU0qYdO+2EpBlNyISSYAa7owlgKaE4Kj9qwdQ0GpUf\nKVUsrsGJkIxiBRNbkSJdfqSI0IpIfPvHeVwO0pX2Stxzzr3S+zVzZne/u8/uc89Y/sw+u2c3VYUk\nSefztFF3QJI0+xkWkqROhoUkqZNhIUnqZFhIkjrNH3UHBuXqq6+uFStWjLobkjSnPPzww1+pqrEz\n65dsWKxYsYKJiYlRd0OS5pQkfz5V3WEoSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIs\nJEmdDAtJUqdL9hfc0lx147tuHHUXZo3PvOkzo+6CGs8sJEmdDAtJUifDQpLUybCQJHUyLCRJnQwL\nSVInw0KS1MmwkCR1GmhYJPmFJPuTfCHJB5I8I8miJLuSPNamV/Vtf1eSQ0kOJrm5r746yb627u4k\nGWS/JUnfa2BhkWQp8C+B8aq6HpgHbATuBHZX1Upgd1smyaq2/jpgHXBPknltd/cCm4GV7bNuUP2W\nJJ1t0MNQ84EFSeYDzwSOAOuBbW39NmBDm18P3F9VJ6vqceAQsCbJEmBhVe2pqgK297WRJA3BwMKi\nqv4CeDvwBHAU+N9V9QfANVV1tG1zFFjcmiwFnuzbxeFWW9rmz6xLkoZkkMNQV9E7W7gWeB7wrCSv\nO1+TKWp1nvpUx9ycZCLJxOTk5IV2WZJ0DoMchnol8HhVTVbV3wAfBl4KHGtDS7Tp8bb9YWB5X/tl\n9IatDrf5M+tnqaqtVTVeVeNjY2Mz+sdI0uVskGHxBLA2yTPb3Us3AY8CO4FNbZtNwANtfiewMcmV\nSa6ldyF7bxuqOpFkbdvPrX1tJElDMLD3WVTVQ0k+CHwOOAV8HtgKPBvYkeQ2eoFyS9t+f5IdwIG2\n/R1Vdbrt7nbgPmAB8GD7SJKGZKAvP6qqtwJvPaN8kt5ZxlTbbwG2TFGfAK6f8Q5KkqbFX3BLkjoZ\nFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZ\nFpKkToaFJKmTYSFJ6jSwsEjy/CSP9H2+keQtSRYl2ZXksTa9qq/NXUkOJTmY5Oa++uok+9q6u9vr\nVSVJQzKwsKiqg1V1Q1XdAKwGvgV8BLgT2F1VK4HdbZkkq4CNwHXAOuCeJPPa7u4FNtN7L/fKtl6S\nNCTDGoa6CfizqvpzYD2wrdW3ARva/Hrg/qo6WVWPA4eANUmWAAurak9VFbC9r40kaQiGFRYbgQ+0\n+Wuq6ihAmy5u9aXAk31tDrfa0jZ/Zv0sSTYnmUgyMTk5OYPdl6TL28DDIsnTgVcB/6Vr0ylqdZ76\n2cWqrVU1XlXjY2NjF9ZRSdI5DePM4ieBz1XVsbZ8rA0t0abHW/0wsLyv3TLgSKsvm6IuSRqSYYTF\na/nuEBTATmBTm98EPNBX35jkyiTX0ruQvbcNVZ1IsrbdBXVrXxtJ0hDMH+TOkzwT+HHg5/vKbwN2\nJLkNeAK4BaCq9ifZARwATgF3VNXp1uZ24D5gAfBg+0iShmSgYVFV3wL+1hm1r9K7O2qq7bcAW6ao\nTwDXD6KPkqRu/oJbktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1\nMiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdBhoWSZ6b5INJvpjk0SQvSbIoya4kj7XpVX3b35XkUJKD\nSW7uq69Osq+tu7u9MU+SNCSDPrN4J/DxqnoB8CLgUeBOYHdVrQR2t2WSrAI2AtcB64B7ksxr+7kX\n2EzvVasr23pJ0pAMLCySLAReBrwHoKq+XVV/BawHtrXNtgEb2vx64P6qOllVjwOHgDVJlgALq2pP\nVRWwva+NJGkIBnlm8XeASeB9ST6f5HeSPAu4pqqOArTp4rb9UuDJvvaHW21pmz+zfpYkm5NMJJmY\nnJyc2b9Gki5jgwyL+cAPA/dW1YuBv6YNOZ3DVNch6jz1s4tVW6tqvKrGx8bGLrS/kqRzGGRYHAYO\nV9VDbfmD9MLjWBtaok2P922/vK/9MuBIqy+boi5JGpKBhUVV/SXwZJLnt9JNwAFgJ7Cp1TYBD7T5\nncDGJFcmuZbehey9bajqRJK17S6oW/vaSJKGYP6A9/8m4P1Jng58CXgDvYDakeQ24AngFoCq2p9k\nB71AOQXcUVWn235uB+4DFgAPto8kaUgGGhZV9QgwPsWqm86x/RZgyxT1CeD6me2dJGm6/AW3JKmT\nYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmT\nYSFJ6mRYSJI6DTQsknw5yb4kjySZaLVFSXYleaxNr+rb/q4kh5IcTHJzX31128+hJHe3N+ZJkoZk\nGGcWP1ZVN1TVUy9BuhPYXVUrgd1tmSSrgI3AdcA64J4k81qbe4HN9F61urKtlyQNySiGodYD29r8\nNmBDX/3+qjpZVY8Dh4A1SZYAC6tqT1UVsL2vjSRpCAYdFgX8QZKHk2xutWuq6ihAmy5u9aXAk31t\nD7fa0jZ/Zv0sSTYnmUgyMTk5OYN/hiRd3gb6Dm7gxqo6kmQxsCvJF8+z7VTXIeo89bOLVVuBrQDj\n4+NTbiNJunDTOrNIsns6tTNV1ZE2PQ58BFgDHGtDS7Tp8bb5YWB5X/NlwJFWXzZFXZI0JOcNiyTP\nSLIIuDrJVe1OpkVJVgDP62j7rCTPeWoe+AngC8BOYFPbbBPwQJvfCWxMcmWSa+ldyN7bhqpOJFnb\n7oK6ta+NJGkIuoahfh54C71geJjvDgl9A3h3R9trgI+0u1znA/+5qj6e5LPAjiS3AU8AtwBU1f4k\nO4ADwCngjqo63fZ1O3AfsAB4sH0kSUNy3rCoqncC70zypqp614XsuKq+BLxoivpXgZvO0WYLsGWK\n+gRw/YUcX5I0c6Z1gbuq3pXkpcCK/jZVtX1A/ZIkzSLTCoskvwv8XeAR4Kmhoad+8yBJusRN99bZ\ncWBV+1GcJOkyM90f5X0B+IFBdkSSNHtN98ziauBAkr3AyaeKVfWqgfRKkjSrTDcsfmWQnZAkzW7T\nvRvqU4PuiCRp9pru3VAn+O7zmJ4OXAH8dVUtHFTHJEmzx3TPLJ7Tv5xkA73nPEmSLgMX9Yjyqvqv\nwCtmuC+SpFlqusNQr+5bfBq93134mwtJukxM926on+mbPwV8md6b7SRJl4HpXrN4w6A7Ikmavab7\n8qNlST6S5HiSY0k+lGRZd0tJ0qVguhe430fv5UTPo/f+64+2miTpMjDdsBirqvdV1an2uQ8YG2C/\nJEmzyHTD4itJXpdkXvu8DvjqdBq27T+f5GNteVGSXUkea9Or+ra9K8mhJAeT3NxXX51kX1t3d3u9\nqiRpSKYbFv8c+FngL4GjwGuA6V70fjPwaN/yncDuqloJ7G7LJFkFbASuA9YB9ySZ19rcC2ym917u\nlW29JGlIphsWvwZsqqqxqlpMLzx+patRuwj+08Dv9JXXA9va/DZgQ1/9/qo6WVWPA4eANUmWAAur\nak97n8b2vjaSpCGYblj8g6r6+lMLVfU14MXTaPfbwL8FvtNXu6aqjrb9HAUWt/pS4Mm+7Q632tI2\nf2b9LEk2J5lIMjE5OTmN7kmSpmO6YfG0M64tLKLjNxpJ/jFwvKoenuYxproOUeepn12s2lpV41U1\nPjbm9XdJminT/QX3fwT+V5IP0vsf9c8CWzra3Ai8KslPAc8AFib5PeBYkiVVdbQNMR1v2x8Glve1\nXwYcafVlU9QlSUMyrTOLqtoO/FPgGDAJvLqqfrejzV1VtayqVtC7cP0/qup19H6vsalttgl4oM3v\nBDYmuTLJtfQuZO9tQ1Unkqxtd0Hd2tdGkjQE0z2zoKoOAAdm4JhvA3YkuQ14Aril7X9/kh3tGKeA\nO6rqdGtzO3AfsAB4sH0kSUMy7bD4flTVJ4FPtvmvAjedY7stTDG8VVUTwPWD66Ek6Xwu6n0WkqTL\ni2EhSeo0lGEoSRqVT73sR0fdhVnjRz/9qYtu65mFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepk\nWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkTgMLiyTPSLI3yR8n2Z/kV1t9UZJdSR5r0/53e9+V\n5FCSg0lu7quvTrKvrbu7vTFPkjQkgzyzOAm8oqpeBNwArEuyFrgT2F1VK4HdbZkkq+i9fvU6YB1w\nT5J5bV/3ApvpvWp1ZVsvSRqSgYVF9XyzLV7RPgWsB7a1+jZgQ5tfD9xfVSer6nHgELAmyRJgYVXt\nqaoCtve1kSQNwUCvWSSZl+QR4Diwq6oeAq6pqqMAbbq4bb4UeLKv+eFWW9rmz6xPdbzNSSaSTExO\nTs7sHyNJl7GBhkVVna6qG4Bl9M4Szvce7amuQ9R56lMdb2tVjVfV+NjY2IV3WJI0paHcDVVVfwV8\nkt61hmNtaIk2Pd42Owws72u2DDjS6sumqEuShmSQd0ONJXlum18AvBL4IrAT2NQ22wQ80OZ3AhuT\nXJnkWnoXsve2oaoTSda2u6Bu7WsjSRqCQb6Dewmwrd3R9DRgR1V9LMkeYEeS24AngFsAqmp/kh3A\nAeAUcEdVnW77uh24D1gAPNg+kqQhGVhYVNWfAC+eov5V4KZztNkCbJmiPgGc73qHJGmA/AW3JKmT\nYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqNMhnQ+ky8sR/eOGouzBr\n/O1f3jfqLkgzzjMLSVInw0KS1MmwkCR1MiwkSZ0G+aa85Uk+keTRJPuTvLnVFyXZleSxNr2qr81d\nSQ4lOZjk5r766iT72rq72xvzJElDMsgzi1PAv66qvw+sBe5Isgq4E9hdVSuB3W2Ztm4jcB29d3Xf\n096yB3AvsJneq1ZXtvWSpCEZWFhU1dGq+lybPwE8CiwF1gPb2mbbgA1tfj1wf1WdrKrHgUPAmiRL\ngIVVtaeqCtje10aSNARDuWaRZAW9V6w+BFxTVUehFyjA4rbZUuDJvmaHW21pmz+zPtVxNieZSDIx\nOTk5k3+CJF3WBh4WSZ4NfAh4S1V943ybTlGr89TPLlZtrarxqhofGxu78M5KkqY00LBIcgW9oHh/\nVX24lY+1oSXa9HirHwaW9zVfBhxp9WVT1CVJQzLIu6ECvAd4tKre0bdqJ7CpzW8CHuirb0xyZZJr\n6V3I3tuGqk4kWdv2eWtfG0nSEAzy2VA3Aj8H7EvySKv9EvA2YEeS24AngFsAqmp/kh3AAXp3Ut1R\nVadbu9uB+4AFwIPtI0kakoGFRVX9T6a+3gBw0znabAG2TFGfAK6fud5Jki6Ev+CWJHUyLCRJnQwL\nSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUqdBPkhwVlv9b7aPuguzxsO/\neeuouyBplvPMQpLUybCQJHUyLCRJnQb5prz3Jjme5At9tUVJdiV5rE2v6lt3V5JDSQ4mubmvvjrJ\nvrbu7va2PEnSEA3yzOI+YN0ZtTuB3VW1EtjdlkmyCtgIXNfa3JNkXmtzL7CZ3mtWV06xT0nSgA0s\nLKrq08DXziivB7a1+W3Ahr76/VV1sqoeBw4Ba5IsARZW1Z6qKmB7XxtJ0pAM+5rFNVV1FKBNF7f6\nUuDJvu0Ot9rSNn9mXZI0RLPlAvdU1yHqPPWpd5JsTjKRZGJycnLGOidJl7thh8WxNrREmx5v9cPA\n8r7tlgFHWn3ZFPUpVdXWqhqvqvGxsbEZ7bgkXc6GHRY7gU1tfhPwQF99Y5Irk1xL70L23jZUdSLJ\n2nYX1K19bSRJQzKwx30k+QDwcuDqJIeBtwJvA3YkuQ14ArgFoKr2J9kBHABOAXdU1em2q9vp3Vm1\nAHiwfSRJQzSwsKiq155j1U3n2H4LsGWK+gRw/Qx2TZJ0gWbLBW5J0ixmWEiSOhkWkqROhoUkqZNh\nIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdOc\nCYsk65IcTHIoyZ2j7o8kXU7mRFgkmQe8G/hJYBXw2iSrRtsrSbp8zImwANYAh6rqS1X1beB+YP2I\n+yRJl41U1aj70CnJa4B1VfUv2vLPAT9SVW88Y7vNwOa2+Hzg4FA7enGuBr4y6k5cIvwuZ5bf58ya\nK9/nD1bV2JnF+aPoyUXIFLWzUq6qtgJbB9+dmZNkoqrGR92PS4Hf5czy+5xZc/37nCvDUIeB5X3L\ny4AjI+qLJF125kpYfBZYmeTaJE8HNgI7R9wnSbpszIlhqKo6leSNwH8H5gHvrar9I+7WTJlTw2az\nnN/lzPL7nFlz+vucExe4JUmjNVeGoSRJI2RYSJI6GRYjkuQFSfYkOZnkF0fdn7nOx8HMnCTvTXI8\nyRdG3Ze5LsnyJJ9I8miS/UnePOo+XSyvWYxIksXADwIbgK9X1dtH3KU5qz0O5k+BH6d3m/VngddW\n1YGRdmyOSvIy4JvA9qq6ftT9mcuSLAGWVNXnkjwHeBjYMBf/2/TMYkSq6nhVfRb4m1H35RLg42Bm\nUFV9GvjaqPtxKaiqo1X1uTZ/AngUWDraXl0cw0KXgqXAk33Lh5mj/yB16UqyAngx8NBoe3JxDAtd\nCqb1OBhpVJI8G/gQ8Jaq+sao+3MxDIshSnJHkkfa53mj7s8lxMfBaNZKcgW9oHh/VX141P25WIbF\nEFXVu6vqhvbxf2Yzx8fBaFZKEuA9wKNV9Y5R9+f74d1QI5LkB4AJYCHwHXp3n6yaq6eoo5bkp4Df\n5ruPg9ky4i7NWUk+ALyc3iO1jwFvrar3jLRTc1SSfwj8IbCP3r9zgF+qqv82ul5dHMNCktTJYShJ\nUifDQpLUybCQJHUyLCRJnQwLSVInw0KaYUluaLfyPrX8qkE/CTfJy5O8dJDH0OXNsJBm3g3A/w+L\nqtpZVW8b8DFfDhgWGhh/ZyH1SfIsYAe9R4bMA34NOAS8A3g28BXg9VV1NMkn6T0U7seA5wK3teVD\nwALgL4Bfb/PjVfXGJPcB/wd4Ab1H1L8B2AS8BHioql7f+vETwK8CVwJ/Bryhqr6Z5MvANuBngCuA\nW4D/C/wRcBqYBN5UVX84iO9Hly/PLKTvtQ44UlUvau9y+DjwLuA1VbUaeC/Q/+vw+VW1BngLvV86\nfxv4ZeD322Ndfn+KY1wFvAL4BeCjwG8B1wEvbENYVwP/HnhlVf0wvV/6/6u+9l9p9XuBX6yqLwP/\nCfitdkyDQjNu/qg7IM0y+4C3J/kN4GPA14HrgV29x/wwDzjat/1TD4Z7GFgxzWN8tKoqyT7gWFXt\nA0iyv+1jGbAK+Ew75tOBPec45qsv4G+TLpphIfWpqj9NspreNYdfB3YB+6vqJedocrJNTzP9f09P\ntflO3/xTy/PbvnZV1Wtn8JjS98VhKKlPe3T8t6rq94C3Az8CjCV5SVt/RZLrOnZzAnjO99GNPwJu\nTPJD7ZjPTPL3BnxM6bwMC+l7vRDYm+QR4N/Ru/7wGuA3kvwx8Ajddx19AljV3lvyzy60A1U1Cbwe\n+ECSP6EXHi/oaPZR4J+0Y/6jCz2m1MW7oSRJnTyzkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmd\nDAtJUqf/B7vzs83GAgh6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = data['sentiment'], data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  0, -1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['message']\n",
    "y = data['sentiment']\n",
    "\n",
    "#X_train = data['message']  # this time we want to look at the text\n",
    "#y_train = data['sentiment']\n",
    "#X_test = test['message']\n",
    "#y_test = test['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algs = [LogisticRegression(random_state = 5), SVC(kernel = 'linear', random_state = 5), SVC(kernel = 'rbf', random_state = 5)\n",
    "        ,MultinomialNB(), KNeighborsClassifier(), DecisionTreeClassifier(max_depth=6),RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kea pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[[ 163   66  180   19]\n",
      " [  19  314  355   49]\n",
      " [  15  125 2530  191]\n",
      " [   5   20  280  890]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.38      0.52       428\n",
      "           0       0.60      0.43      0.50       737\n",
      "           1       0.76      0.88      0.82      2861\n",
      "           2       0.77      0.74      0.76      1195\n",
      "\n",
      "    accuracy                           0.75      5221\n",
      "   macro avg       0.73      0.61      0.65      5221\n",
      "weighted avg       0.74      0.75      0.73      5221\n",
      "\n",
      "F1_score:  0.733\n",
      "-------------------------------------------------------\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=5, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "[[ 177   84  153   14]\n",
      " [  18  364  312   43]\n",
      " [  24  176 2454  207]\n",
      " [   6   30  275  884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.41      0.54       428\n",
      "           0       0.56      0.49      0.52       737\n",
      "           1       0.77      0.86      0.81      2861\n",
      "           2       0.77      0.74      0.75      1195\n",
      "\n",
      "    accuracy                           0.74      5221\n",
      "   macro avg       0.72      0.63      0.66      5221\n",
      "weighted avg       0.74      0.74      0.74      5221\n",
      "\n",
      "F1_score:  0.735\n",
      "-------------------------------------------------------\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=5, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "[[  92   68  252   16]\n",
      " [   6  271  413   47]\n",
      " [   3  123 2487  248]\n",
      " [   2   10  310  873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.21      0.35       428\n",
      "           0       0.57      0.37      0.45       737\n",
      "           1       0.72      0.87      0.79      2861\n",
      "           2       0.74      0.73      0.73      1195\n",
      "\n",
      "    accuracy                           0.71      5221\n",
      "   macro avg       0.73      0.55      0.58      5221\n",
      "weighted avg       0.72      0.71      0.69      5221\n",
      "\n",
      "F1_score:  0.691\n",
      "-------------------------------------------------------\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "[[  75   13  327   13]\n",
      " [   2  134  564   37]\n",
      " [   0   15 2703  143]\n",
      " [   2    3  396  794]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.18      0.30       428\n",
      "           0       0.81      0.18      0.30       737\n",
      "           1       0.68      0.94      0.79      2861\n",
      "           2       0.80      0.66      0.73      1195\n",
      "\n",
      "    accuracy                           0.71      5221\n",
      "   macro avg       0.81      0.49      0.53      5221\n",
      "weighted avg       0.75      0.71      0.67      5221\n",
      "\n",
      "F1_score:  0.665\n",
      "-------------------------------------------------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[[  34  362   31    1]\n",
      " [   6  652   76    3]\n",
      " [  18 1991  831   21]\n",
      " [  15  607  397  176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.08      0.14       428\n",
      "           0       0.18      0.88      0.30       737\n",
      "           1       0.62      0.29      0.40      2861\n",
      "           2       0.88      0.15      0.25      1195\n",
      "\n",
      "    accuracy                           0.32      5221\n",
      "   macro avg       0.54      0.35      0.27      5221\n",
      "weighted avg       0.61      0.32      0.33      5221\n",
      "\n",
      "F1_score:  0.328\n",
      "-------------------------------------------------------\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "[[  20   53  339   16]\n",
      " [   4  152  543   38]\n",
      " [   2  105 2464  290]\n",
      " [   0    1  663  531]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.05      0.09       428\n",
      "           0       0.49      0.21      0.29       737\n",
      "           1       0.61      0.86      0.72      2861\n",
      "           2       0.61      0.44      0.51      1195\n",
      "\n",
      "    accuracy                           0.61      5221\n",
      "   macro avg       0.62      0.39      0.40      5221\n",
      "weighted avg       0.61      0.61      0.56      5221\n",
      "\n",
      "F1_score:  0.559\n",
      "-------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "[[  94   64  266    4]\n",
      " [   4  263  457   13]\n",
      " [   4  126 2633   98]\n",
      " [   1   13  544  637]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.22      0.35       428\n",
      "           0       0.56      0.36      0.44       737\n",
      "           1       0.68      0.92      0.78      2861\n",
      "           2       0.85      0.53      0.65      1195\n",
      "\n",
      "    accuracy                           0.69      5221\n",
      "   macro avg       0.75      0.51      0.56      5221\n",
      "weighted avg       0.72      0.69      0.67      5221\n",
      "\n",
      "F1_score:  0.667\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(algs)):\n",
    "    text_clf = Pipeline([('tfidf', CountVectorizer(lowercase = True,stop_words='english', \n",
    "                                                   ngram_range=(1, 2), analyzer='word',max_df = 0.8)), ('clf', algs[i]),])\n",
    "    ##lowercase = True,stop_words='english', ngram_range=(1, 2), analyzer='word',max_df = 0.8\n",
    "    text_clf.fit(X_train, y_train)  \n",
    "    predictions = text_clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(algs[i])\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print('F1_score: ',round(metrics.f1_score(y_test,predictions, average = 'weighted'),3))\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ada = ADASYN(random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_res, y_train_res = ada.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from imblearn.under_sampling import NearMiss \n",
    "#nr = NearMiss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_res, y_train_res = nr.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## balancing the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class size to up/down sample by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_size = int(len(data[data['sentiment']==1])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperating the four classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_1 = data[data['sentiment']==-1]\n",
    "class_2 = data[data['sentiment']==0]\n",
    "class_3 = data[data['sentiment']==1]\n",
    "class_4 = data[data['sentiment']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upsampling classes 1, 2, and 4 & downsampling class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_up = resample(class_1,replace=True,n_samples=class_size, random_state=27)\n",
    "class_2_up = resample(class_2,replace=True,n_samples=class_size, random_state=27)\n",
    "class_4_up = resample(class_4,replace=True,n_samples=class_size, random_state=27)\n",
    "class_3_down = resample(class_3,replace=False,n_samples=class_size, random_state=27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.concat([class_1_up, class_2_up, class_4_up,class_3_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZ0MC0lSJ8NCktTJsJAkdTIsJEmd/h8OY6YGMG/XegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = res_df['sentiment'], data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equal distribution of classes as shown on the count plot, therefore classes are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_res = res_df['message']\n",
    "y_res = res_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kea pc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=5, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "[[1042   20    8    6]\n",
      " [  15  980   54   25]\n",
      " [  52  122  731  131]\n",
      " [   5   21   72  981]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.97      0.95      1076\n",
      "           0       0.86      0.91      0.88      1074\n",
      "           1       0.85      0.71      0.77      1036\n",
      "           2       0.86      0.91      0.88      1079\n",
      "\n",
      "    accuracy                           0.88      4265\n",
      "   macro avg       0.87      0.87      0.87      4265\n",
      "weighted avg       0.87      0.88      0.87      4265\n",
      "\n",
      "F1_score:  0.873\n",
      "-------------------------------------------------------\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=5, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "[[1040   21    9    6]\n",
      " [  15  978   56   25]\n",
      " [  44  134  748  110]\n",
      " [   4   21   83  971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.97      0.95      1076\n",
      "           0       0.85      0.91      0.88      1074\n",
      "           1       0.83      0.72      0.77      1036\n",
      "           2       0.87      0.90      0.89      1079\n",
      "\n",
      "    accuracy                           0.88      4265\n",
      "   macro avg       0.87      0.87      0.87      4265\n",
      "weighted avg       0.87      0.88      0.87      4265\n",
      "\n",
      "F1_score:  0.874\n",
      "-------------------------------------------------------\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=5, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "[[1018   35   10   13]\n",
      " [  19  963   44   48]\n",
      " [  41  167  653  175]\n",
      " [   2   16   72  989]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.95      0.94      1076\n",
      "           0       0.82      0.90      0.85      1074\n",
      "           1       0.84      0.63      0.72      1036\n",
      "           2       0.81      0.92      0.86      1079\n",
      "\n",
      "    accuracy                           0.85      4265\n",
      "   macro avg       0.85      0.85      0.84      4265\n",
      "weighted avg       0.85      0.85      0.85      4265\n",
      "\n",
      "F1_score:  0.845\n",
      "-------------------------------------------------------\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "[[1040    8   15   13]\n",
      " [  51  903   71   49]\n",
      " [ 101   76  683  176]\n",
      " [  12    8   59 1000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.97      0.91      1076\n",
      "           0       0.91      0.84      0.87      1074\n",
      "           1       0.82      0.66      0.73      1036\n",
      "           2       0.81      0.93      0.86      1079\n",
      "\n",
      "    accuracy                           0.85      4265\n",
      "   macro avg       0.85      0.85      0.85      4265\n",
      "weighted avg       0.85      0.85      0.85      4265\n",
      "\n",
      "F1_score:  0.846\n",
      "-------------------------------------------------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[[ 644  420    5    7]\n",
      " [  22 1044    6    2]\n",
      " [  56  811  159   10]\n",
      " [  47  666    8  358]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.60      0.70      1076\n",
      "           0       0.35      0.97      0.52      1074\n",
      "           1       0.89      0.15      0.26      1036\n",
      "           2       0.95      0.33      0.49      1079\n",
      "\n",
      "    accuracy                           0.52      4265\n",
      "   macro avg       0.76      0.51      0.49      4265\n",
      "weighted avg       0.76      0.52      0.50      4265\n",
      "\n",
      "F1_score:  0.495\n",
      "-------------------------------------------------------\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "[[288 385 174 229]\n",
      " [ 85 593 170 226]\n",
      " [ 67 223 379 367]\n",
      " [ 51  52 103 873]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.27      0.37      1076\n",
      "           0       0.47      0.55      0.51      1074\n",
      "           1       0.46      0.37      0.41      1036\n",
      "           2       0.52      0.81      0.63      1079\n",
      "\n",
      "    accuracy                           0.50      4265\n",
      "   macro avg       0.51      0.50      0.48      4265\n",
      "weighted avg       0.51      0.50      0.48      4265\n",
      "\n",
      "F1_score:  0.479\n",
      "-------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "[[1031   22   12   11]\n",
      " [   4  968   59   43]\n",
      " [  22  188  653  173]\n",
      " [   0   28   67  984]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.96      0.97      1076\n",
      "           0       0.80      0.90      0.85      1074\n",
      "           1       0.83      0.63      0.71      1036\n",
      "           2       0.81      0.91      0.86      1079\n",
      "\n",
      "    accuracy                           0.85      4265\n",
      "   macro avg       0.85      0.85      0.85      4265\n",
      "weighted avg       0.85      0.85      0.85      4265\n",
      "\n",
      "F1_score:  0.849\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(algs)):\n",
    "    text_clf = Pipeline([('count_vec', CountVectorizer(lowercase = True,stop_words='english', \n",
    "                                                   ngram_range=(1, 2), analyzer='word')), ('clf', algs[i]),])\n",
    "   \n",
    "    text_clf.fit(X_train, y_train)  \n",
    "    predictions = text_clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(algs[i])\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print('F1_score: ',round(metrics.f1_score(y_test,predictions, average = 'weighted'),3))\n",
    "    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
